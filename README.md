# AI Photo Editing â€“ Background Inpainting Web App

## Overview
This project is a web application that allows users to **replace the background of a subject in an image** with a new scene generated by **Stable Diffusion** from a text prompt. It uses the **Segment Anything Model (SAM)** from Meta/Facebook to segment the subject and then applies **inpainting** to fill in the background.  

The app is interactive, allowing users to select points on the subject, preview the segmentation mask, and generate high-quality background modifications.  

---

## Features
- Upload any image and select points on the subject to generate a segmentation mask using SAM.
- Preview the segmentation mask before inpainting.
- Replace the background using a text prompt with **Stable Diffusion inpainting pipeline**.
- Adjust the following parameters:
  - **CFG Scale** (Classifier-Free Guidance Scale)
  - **Random seed** for reproducibility
  - Option to **invert the mask** (infill the subject instead of the background)
- Preloaded example images for quick testing.

---

## Usage 
1. **Run the notebook (`starter.ipynb`)** to:
   - Load the SAM model and processor.
   - Define helper functions to generate segmentation masks and inpaint backgrounds.

2. **Launch the web app (`app.py`)**:
```bash
python app.py
